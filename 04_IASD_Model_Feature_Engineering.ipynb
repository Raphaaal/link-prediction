{"nbformat":4,"nbformat_minor":0,"metadata":{"jupytext":{"encoding":"# -*- coding: utf-8 -*-","formats":"py:light,ipynb"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.4"},"colab":{"name":"REAL_04_Model_Feature_Engineering.ipynb","provenance":[],"collapsed_sections":["wDwewWxGpJHb","Pu5X15uIpJHc","Wg6shFo0YTHU"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZoaqhgJQC_fC"},"source":["# Setup\n","\n","Install the necessary libraries in your Colab notebook environment and connect to your hosted Neo4J Sandbox."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JmHymBmsVYqx","executionInfo":{"status":"ok","timestamp":1623163483144,"user_tz":-120,"elapsed":3244,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}},"outputId":"ef1e2d34-d823-4ee5-ed88-6b5a3e66bdfb"},"source":["!pip install neo4j pyspark"],"execution_count":181,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.2)\n","Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fhmJ1QEdC-4e","executionInfo":{"status":"ok","timestamp":1623159823803,"user_tz":-120,"elapsed":77,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}}},"source":["ip = \"54.172.14.140\"\n","bolt_port = \"7687\"\n","username = \"neo4j\"\n","password = \"rifle-sponsor-beliefs\""],"execution_count":153,"outputs":[]},{"cell_type":"code","metadata":{"id":"RI-e7X2UuOgR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623159823806,"user_tz":-120,"elapsed":70,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}},"outputId":"ff26113a-294b-4483-a1ba-50b98252ddf9"},"source":["from neo4j import GraphDatabase\n","\n","driver = GraphDatabase.driver(\"bolt://\" + ip + \":\" + bolt_port, auth=(username, password))\n","\n","print(driver.address) # your-sandbox-ip:your-sandbox-bolt-port"],"execution_count":154,"outputs":[{"output_type":"stream","text":["54.172.14.140:7687\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pn3TAwvf07Wq","executionInfo":{"status":"ok","timestamp":1623163483152,"user_tz":-120,"elapsed":50,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}}},"source":["from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"execution_count":182,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"efG3CA7jrfIO","executionInfo":{"status":"ok","timestamp":1623163483157,"user_tz":-120,"elapsed":51,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}},"outputId":"bacd0a61-215d-4abb-912a-2f15233fd1a2"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":183,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tImzcaWsrisK","executionInfo":{"status":"ok","timestamp":1623163484162,"user_tz":-120,"elapsed":7,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}}},"source":["save_folder = '/content/gdrive/My Drive/IASD_vacations/IASD_link_prediction/link-prediction/notebooks/data/'"],"execution_count":184,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XX_KGQOcVDyX"},"source":["# Objective\n","\n","We are going to train a binary classifier to predict wether a link should exist between two *Author* nodes.\n","\n","Each pair of *Author*s will be described with a feature vector and labeled with either 1 (if these two authors have collaborated) or 0 (if they have not)."]},{"cell_type":"markdown","metadata":{"id":"26Fmz1FypJHX"},"source":["# Feature Engineering\n","\n","Let's generate features for our link prediction classifier. These features will describe a pair of *Author*s by using:\n","- graph topology measures\n","- community detection measures\n","\n","\n","We will identify the nodes by their ID, compute graph measures for these nodes in Neo4J and return a DataFrame with these new features describing each pair of nodes in the train and test set."]},{"cell_type":"markdown","metadata":{"id":"iz-4iaqtpJHa"},"source":["Load the CSV files saved in the train/test notebook."]},{"cell_type":"code","metadata":{"id":"OHfF6Fz8pJHa","executionInfo":{"status":"ok","timestamp":1623154040187,"user_tz":-120,"elapsed":19415,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}}},"source":["df_train_under = spark.read.csv(save_folder + 'df_train_under.csv/*.csv', header=True, inferSchema=True).cache()\n","df_test_under = spark.read.csv(save_folder + 'df_test_under.csv/*.csv', header=True, inferSchema=True).cache()"],"execution_count":146,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s4q1TPS03gQs"},"source":["Firstly, for Neo4J to be able to manipulate our train and test pairs, we need to feed them as lists of dictionaries. This will enable us to consider each element in this list as a parameter for a Neo4J query. This element's attributes will be accessible to the query."]},{"cell_type":"markdown","metadata":{"id":"fH6mU1qpkXM0"},"source":["\n","- Transform each data frame into a list of dictionaries in the following form\n","\n","```\n","[\n","  {\n","  \"node1\": 15589,\n","  \"node2\": 2567,\n","  \"label\": 1\n","  } ,\n","  ... ,\n","  {\n","  \"node1\": 5466,\n","  \"node2\": 78122,\n","  \"label\": 0\n","  }\n","]\n","\n","```"]},{"cell_type":"code","metadata":{"id":"zOr71l_w5vyn"},"source":["### Using Python's list comprehension syntax\n","\n","df_train_under_pairs = [{\"node1\": ... , \"node2\": ... , \"label\": ...}  for ... , ... , ... in df_train_under. ...]\n","df_test_under_pairs = [{\"node1\": ... , \"node2\": ... , \"label\": ...}  for ... , ... , ... in df_test_under. ...]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"gV3ZTmuG4UNd","executionInfo":{"status":"ok","timestamp":1623154042369,"user_tz":-120,"elapsed":2227,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}}},"source":["#@title Solution\n","\n","df_train_under_pairs = [{\"node1\": node1, \"node2\": node2, 'label':label}  for node1, node2, label in df_train_under.select(\"node1\", \"node2\", \"label\").collect()]\n","df_test_under_pairs = [{\"node1\": node1, \"node2\": node2, 'label':label}  for node1, node2, label in df_test_under.select(\"node1\", \"node2\", \"label\").collect()]"],"execution_count":147,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wDwewWxGpJHb"},"source":["## Generating graphy features\n","\n","We will start by creating 3 features extracted from the graph topology to describe each pair of nodes: \n","- [common neighbors](https://neo4j.com/docs/graph-data-science/current/alpha-algorithms/common-neighbors/)\n","- [preferential attachment](https://neo4j.com/docs/graph-data-science/current/alpha-algorithms/preferential-attachment/)\n","- [total neighbors](https://neo4j.com/docs/graph-data-science/current/alpha-algorithms/total-neighbors/)\n","\n","We want a final Data Frame with the following structure:\n","\n","| node1 | node2 | label | cn | pa | tn |"]},{"cell_type":"markdown","metadata":{"id":"epw1BpAtkGHs"},"source":["By using the *UNWIND* clause, we can manipulate each element in a list as an individual row in Cypher.\n","\n","For example:\n","```\n","# A list of students dictionaries\n","my_list = [{ \"id\": '0001', \"age\": 28}, {\"id\": 0002, \"age\": 35}]\n","\n","# A parameterized query to retrieve each students' name from its attributes\n","query = \n","\"\"\" \n","  UNWIND $list_of_students as student // We use a dollar sign to denote variables\n","    MATCH (s:Student) \n","    WHERE ID(s) = student.id AND s.age = student.age\n","    RETURN s.name\n","\"\"\"\n","\n","with driver.session() as session:\n","    result = session.run(query=query, parameters={\"list_of_students\": my_list})\n","```"]},{"cell_type":"markdown","metadata":{"id":"IAwNbtpw4of_"},"source":["- Complete the following function to compute the 3 graph measures for pairs of nodes.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"bqC1WC8mA0wX","executionInfo":{"status":"ok","timestamp":1623153404731,"user_tz":-120,"elapsed":323,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}}},"source":["def add_graphy_features(pairs, rel_type):\n","    # Common neighbors\n","    query = \"\"\"\n","      UNWIND $... AS ...\n","        MATCH (p1) WHERE ... = ...\n","        MATCH (p2) WHERE ... = ...\n","        RETURN \n","          ... AS node1,\n","          ... AS node2,\n","          ... AS label,\n","          gds.alpha.linkprediction.commonNeighbors(... , ... , {relationshipQuery: $...}) AS cn\n","    \"\"\"\n","    params = {\n","        \"...\": ... , \n","        \"...\": ...\n","    }\n","    with driver.session() as session:\n","        result = session.run(query, params)\n","        features_cn = spark.createDataFrame([dict(record) for record in result]) \n","\n","    # Preferential attachment\n","    query = \"\"\"\n","      UNWIND $... AS ...\n","        MATCH (p1) WHERE ... = ...\n","        MATCH (p2) WHERE ... = ...\n","        RETURN \n","          ... AS node1,\n","          ... AS node2,\n","          ... AS label,\n","          gds.alpha.linkprediction.preferentialAttachment(... , ... , {relationshipQuery: $...}) AS pa\n","    \"\"\"\n","    params = {\n","        \"...\": ... , \n","        \"...\": ...\n","    }\n","    with driver.session() as session:\n","        result = session.run(query, params)\n","        features_pa = spark.createDataFrame([dict(record) for record in result])\n","\n","    # Total neighbors\n","    query = \"\"\"\n","      UNWIND $... AS ...\n","        MATCH (p1) WHERE ... = ...\n","        MATCH (p2) WHERE ... = ...\n","        RETURN \n","          ... AS node1,\n","          ... AS node2,\n","          ... AS label,\n","          gds.alpha.linkprediction.totalNeighbors(... , ... , {relationshipQuery: $...}) AS tn\n","    \"\"\"\n","    params = {\n","        \"...\": ... , \n","        \"...\": ...\n","    }\n","    with driver.session() as session:\n","        result = session.run(quer, params)\n","        features_tn = spark.createDataFrame([dict(record) for record in result])  \n","\n","    # Join the three feature dfs\n","    final_df = ... .join(\n","        ... , on=[...], how='...'\n","        ).join(\n","        ... , on=[...], how='...'\n","        )\n","\n","    return final_df"],"execution_count":136,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"NvCaxBKd-xu2","executionInfo":{"status":"ok","timestamp":1623100860454,"user_tz":-120,"elapsed":257,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}}},"source":["#@title Hint\n","\n","def add_graphy_features(pairs, rel_type):\n","    # Common neighbors\n","    query = \"\"\"\n","      UNWIND $pairs AS pair\n","        MATCH (p1) WHERE ID(p1) = ...\n","        MATCH (p2) WHERE ID(p2) = ...\n","        RETURN \n","          ... AS node1,\n","          ... AS node2,\n","          ... AS label,\n","          gds.alpha.linkprediction.commonNeighbors(... , ... , {relationshipQuery: $relType}) AS cn\n","    \"\"\"\n","    params = {\n","        \"pairs\": pairs, \n","        \"relType\": rel_type\n","        }\n","    with driver.session() as session:\n","        result = session.run(query, params)\n","        features_cn = spark.createDataFrame([dict(record) for record in result]) \n","\n","    # Preferential attachment\n","    query = \"\"\"\n","      UNWIND $pairs AS pair\n","        MATCH (p1) WHERE ID(p1) = ...\n","        MATCH (p2) WHERE ID(p2) = ...\n","        RETURN \n","          ... AS node1,\n","          ... AS node2,\n","          ... AS label,\n","          gds.alpha.linkprediction.preferentialAttachment(... , ... , {relationshipQuery: $relType}) AS pa\n","    \"\"\"\n","    params = {\n","        \"pairs\": pairs, \n","        \"relType\": rel_type\n","        }\n","    with driver.session() as session:\n","        result = session.run(query, params)\n","        features_pa = spark.createDataFrame([dict(record) for record in result])\n","\n","    # Total neighbors\n","    query = \"\"\"\n","      UNWIND $pairs AS pair\n","        MATCH (p1) WHERE ID(p1) = ...\n","        MATCH (p2) WHERE ID(p2) = ...\n","        RETURN \n","          ... AS node1,\n","          ... AS node2,\n","          ... AS label,\n","          gds.alpha.linkprediction.totalNeighbors(... , ... , {relationshipQuery: $relType}) AS tn\n","    \"\"\"\n","    params = {\n","        \"pairs\": pairs, \n","        \"relType\": rel_type\n","        }\n","    with driver.session() as session:\n","        result = session.run(query, params)\n","        features_tn = spark.createDataFrame([dict(record) for record in result])  \n","\n","    # Join the three feature dfs\n","    final_df = ... .join(\n","        ... , on=[\"node1\", \"node2\", \"label\"], how='inner'\n","        ).join(\n","        ... , on=[\"node1\", \"node2\", \"label\"], how='inner'\n","        )\n","\n","    return final_df"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"dq097FZPpJHb","cellView":"form","executionInfo":{"status":"ok","timestamp":1623162558304,"user_tz":-120,"elapsed":204,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}}},"source":["#@title Solution\n","\n","def add_graphy_features(pairs, rel_type):\n","    query = \"\"\"\n","      UNWIND $pairs AS pair\n","        MATCH (p1) WHERE ID(p1) = pair.node1\n","        MATCH (p2) WHERE ID(p2) = pair.node2\n","        RETURN \n","          pair.node1 AS node1,\n","          pair.node2 AS node2,\n","          pair.label AS label,\n","          gds.alpha.linkprediction.commonNeighbors(p1, p2, {relationshipQuery: $relType}) AS cn\n","    \"\"\"\n","    params = {\n","        \"pairs\": pairs, \n","        \"relType\": rel_type\n","        }\n","    with driver.session() as session:\n","        result = session.run(query, params)\n","        features_cn = spark.createDataFrame([dict(record) for record in result]) \n","\n","    query = \"\"\"\n","      UNWIND $pairs AS pair\n","        MATCH (p1) WHERE ID(p1) = pair.node1\n","        MATCH (p2) WHERE ID(p2) = pair.node2\n","        RETURN \n","          pair.node1 AS node1,\n","          pair.node2 AS node2,\n","          pair.label AS label,\n","          gds.alpha.linkprediction.preferentialAttachment(p1, p2, {relationshipQuery: $relType}) AS pa\n","    \"\"\"\n","    params = {\n","        \"pairs\": pairs, \n","        \"relType\": rel_type\n","        }\n","    with driver.session() as session:\n","        result = session.run(query, params)\n","        features_pa = spark.createDataFrame([dict(record) for record in result])\n","\n","    query = \"\"\"\n","      UNWIND $pairs AS pair\n","        MATCH (p1) WHERE ID(p1) = pair.node1\n","        MATCH (p2) WHERE ID(p2) = pair.node2\n","        RETURN \n","          pair.node1 AS node1,\n","          pair.node2 AS node2,\n","          pair.label AS label,\n","          gds.alpha.linkprediction.totalNeighbors(p1, p2, {relationshipQuery: $relType}) AS tn\n","    \"\"\"\n","    params = {\n","        \"pairs\": pairs, \n","        \"relType\": rel_type\n","        }\n","    with driver.session() as session:\n","        result = session.run(query, params)\n","        features_tn = spark.createDataFrame([dict(record) for record in result])  \n","\n","    final_df = features_cn.join(\n","        features_pa, on=[\"node1\", \"node2\", \"label\"], how='inner'\n","        ).join(\n","        features_tn, on=[\"node1\", \"node2\", \"label\"], how='inner'\n","        )\n","\n","    return final_df"],"execution_count":171,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ygZi81CRpJHb"},"source":["Let's apply the function to our training DataFrame and do a quick sanity check of the number of resulting rows (that should be the same).\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zgE3340dAlmk","executionInfo":{"status":"ok","timestamp":1623162760487,"user_tz":-120,"elapsed":201064,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}},"outputId":"4ac26d56-1fa2-4bec-c9d7-55b020d64947"},"source":["print('Counts before applying graph features engineering: ')\n","print(df_train_under.count())\n","print(df_test_under.count())\n","\n","df_train_under_graph_f = add_graphy_features(df_train_under_pairs, \"CO_AUTHOR_EARLY\")\n","df_test_under_graph_f = add_graphy_features(df_test_under_pairs, \"CO_AUTHOR_LATE\")\n","\n","print('Counts after applying graph features engineering: ')\n","print(df_train_under_graph_f.count())\n","print(df_test_under_graph_f.count())"],"execution_count":172,"outputs":[{"output_type":"stream","text":["Counts before applying graph features engineering: \n","162234\n","121380\n","Counts after applying graph features engineering: \n","162234\n","121380\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4OC8AqJoSuOs"},"source":["Let's see how it looks:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbnB6fsPSbvt","executionInfo":{"status":"ok","timestamp":1623162763151,"user_tz":-120,"elapsed":2702,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}},"outputId":"44076182-1a30-4c06-f2f0-0c56c8b1ce36"},"source":["df_train_under_graph_f.filter(F.col('label') == 0).show(5)\n","df_test_under_graph_f.filter(F.col('label') == 1).show(5)"],"execution_count":173,"outputs":[{"output_type":"stream","text":["+-----+------+-----+---+----+----+\n","|node1| node2|label| cn|  pa|  tn|\n","+-----+------+-----+---+----+----+\n","|  975|224292|    0|0.0|36.0|20.0|\n","|  979|205473|    0|2.0|65.0|16.0|\n","|  980| 58023|    0|1.0|27.0|11.0|\n","|  980|191694|    0|0.0| 9.0| 6.0|\n","| 1028|  9854|    0|1.0|24.0|10.0|\n","+-----+------+-----+---+----+----+\n","only showing top 5 rows\n","\n","+------+------+-----+---+----+----+\n","| node1| node2|label| cn|  pa|  tn|\n","+------+------+-----+---+----+----+\n","| 84788| 84790|    1|2.0| 9.0| 4.0|\n","|117647|117649|    1|5.0|48.0| 9.0|\n","|139973|236514|    1|1.0|10.0| 6.0|\n","| 77249|188365|    1|4.0|60.0|13.0|\n","|129886|129887|    1|1.0| 6.0| 4.0|\n","+------+------+-----+---+----+----+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Pu5X15uIpJHc"},"source":["## Generating community features\n","\n","Community detection algorithms evaluate how a group is clustered or partitioned. Nodes are considered more similar to nodes that fall in their community than to nodes in other communities.\n","\n","We will extract one feature based on a community detection algorithm:\n","\n","- [Louvain community](https://neo4j.com/docs/graph-data-science/current/algorithms/louvain/)\n","\n","The Louvain algorithm returns intermediate communities found in the graph. We will add a property to each node containing the first community that the algorithm found for this specific node. Thus, it will constitue a categorical feature : the first community to which each node belongs. As we are considering pairs of nodes, we will derive a *'same_community_louvain'* binary feature (True or False) to further describe each pair of nodes. \n","\n","Note that we need to restrict the execution of the Louvain community detection algorithm to the train and test subgraphs separately."]},{"cell_type":"markdown","metadata":{"id":"Rn7T8-_O48Rs"},"source":["- Set a property on each node in the *CO_AUTHOR_EARLY* subgraph, containing the first community ID that the Louvain algorithm found for this node."]},{"cell_type":"code","metadata":{"id":"34hmbUehpJHc","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1623160341339,"user_tz":-120,"elapsed":23566,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}},"outputId":"c967807e-8305-4836-ba97-78ac77351ecb"},"source":["query = \"\"\"\n","  CALL gds.louvain.stream({\n","    nodeProjection: 'Author',\n","    relationshipProjection: {\n","      CO_AUTHOR_EARLY: {\n","        type: 'CO_AUTHOR_EARLY',\n","        orientation: 'UNDIRECTED'\n","      }\n","    },\n","    includeIntermediateCommunities: true\n","  })\n","  YIELD nodeId, communityId, intermediateCommunityIds\n","  WITH gds.util.asNode(nodeId) AS node, intermediateCommunityIds[0] AS smallestCommunity\n","  SET node.louvainTrain = smallestCommunity;\n","  \"\"\"\n","\n","with driver.session() as session:\n","    display(session.run(query).consume().counters)"],"execution_count":158,"outputs":[{"output_type":"display_data","data":{"text/plain":["{'properties_set': 80299}"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"mlfAQ55d5UjJ"},"source":["- Similarly, set a property on each node in the *CO_AUTHOR_LATE* subgraph, containing the first community ID that the Louvain algorithm found for this node."]},{"cell_type":"code","metadata":{"id":"mwPYWSOdpJHc","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1623160434607,"user_tz":-120,"elapsed":11484,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}},"outputId":"33690f0f-57c7-4c78-b11f-4de8538c3234"},"source":["query = \"\"\"\n","  CALL gds.louvain.stream({\n","    nodeProjection: 'Author',\n","    relationshipProjection: {\n","      CO_AUTHOR_LATE: {\n","        type: 'CO_AUTHOR_LATE',\n","        orientation: 'UNDIRECTED'\n","      }\n","    },\n","    includeIntermediateCommunities: true\n","  })\n","  YIELD nodeId, communityId, intermediateCommunityIds\n","  WITH gds.util.asNode(nodeId) AS node, intermediateCommunityIds[0] AS smallestCommunity\n","  SET node.louvainTest = smallestCommunity;\n","  \"\"\"\n","\n","with driver.session() as session:\n","    display(session.run(query).consume().counters)"],"execution_count":159,"outputs":[{"output_type":"display_data","data":{"text/plain":["{'properties_set': 80299}"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"liWanN3o6LK3"},"source":["Now, each node in our graph contains 2 new properties. What are the names of these properties? \n","\n","\n","**Hint:** Feel free to use the Neo4J Browser if it doesn't look intuitive from the code blocks above."]},{"cell_type":"code","metadata":{"cellView":"form","id":"5iUwKSPo6xpJ"},"source":["#@title Solution\n","\n","\"\"\"\n","- louvainTrain: the ID of the first community found for the node when using CO_AUTHOR_EARLY edges only\n","- louvainTest:  the ID of the first community found for the node when using CO_AUTHOR_LATE edges only\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UbG0VSN36YJf"},"source":["Let's now build a derived feature to express for each pair wether the nodes belong to the same Louvain community or not.\n","\n","- Complete the function below to create this derived feature for each pair of nodes"]},{"cell_type":"code","metadata":{"id":"MwKKEglh9B7J"},"source":["def add_community_feature(pairs, louvain_prop):\n","    query = \"\"\"\n","      UNWIND ... AS ...\n","      MATCH (p1) WHERE ...\n","      MATCH (p2) WHERE ...\n","      RETURN \n","        ... AS node1,\n","        ... AS node2,\n","        ... AS label,\n","        gds.alpha.linkprediction.sameCommunity(... , ... , ...) AS sl\n","    \"\"\"\n","    params = {\n","    \"...\": ... ,\n","    \"...\": ...\n","    }\n","    with driver.session() as session:\n","        result = session.run(query, params)\n","        features_sl = spark.createDataFrame([dict(record) for record in result])\n","    \n","    return features_sl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EsdrnftopJHc","cellView":"form","executionInfo":{"status":"ok","timestamp":1623161965572,"user_tz":-120,"elapsed":213,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}}},"source":["#@title Solution\n","\n","def add_community_feature(pairs, louvain_prop):\n","    query = \"\"\"\n","      UNWIND $pairs AS pair\n","      MATCH (p1) WHERE ID(p1) = pair.node1\n","      MATCH (p2) WHERE ID(p2) = pair.node2\n","      RETURN \n","        pair.node1 AS node1,\n","        pair.node2 AS node2,\n","        pair.label AS label,\n","        gds.alpha.linkprediction.sameCommunity(p1, p2, $louvainProp) AS sl\n","    \"\"\"\n","    params = {\n","    \"pairs\": pairs,\n","    \"louvainProp\": louvain_prop\n","    }\n","    with driver.session() as session:\n","        result = session.run(query, params)\n","        features_sl = spark.createDataFrame([dict(record) for record in result])\n","    \n","    return features_sl"],"execution_count":164,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n31STYVnB2Qu"},"source":["Let's apply the function to our training DataFrame and do a quick sanity check of the number of resulting rows (that should be the same)."]},{"cell_type":"code","metadata":{"id":"rdF3yinbpJHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623162822602,"user_tz":-120,"elapsed":59549,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}},"outputId":"77080087-9f39-481e-facf-0aabc9631fc8"},"source":["print('Counts before applying community feature engineering: ')\n","print(df_train_under.count())\n","print(df_test_under.count())\n","\n","df_train_under_community_f = add_community_feature(df_train_under_pairs, \"louvainTrain\")\n","df_test_under_community_f = add_community_feature(df_test_under_pairs, \"louvainTest\")\n","\n","print('Counts after applying community feature engineering: ')\n","print(df_train_under_community_f.count())\n","print(df_test_under_community_f.count())"],"execution_count":174,"outputs":[{"output_type":"stream","text":["Counts before applying community feature engineering: \n","162234\n","121380\n","Counts after applying community feature engineering: \n","162234\n","121380\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rTd8AO8wYIH6"},"source":["Let's see how it looks:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sjFh7FdqYHcg","executionInfo":{"status":"ok","timestamp":1623163045692,"user_tz":-120,"elapsed":435,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}},"outputId":"b73aec00-ded0-427f-f620-fe855a346626"},"source":["df_train_under_community_f.filter(F.col('label') == 0).show(5)\n","df_test_under_community_f.filter(F.col('label') == 1).show(5)"],"execution_count":178,"outputs":[{"output_type":"stream","text":["+-----+-----+------+---+\n","|label|node1| node2| sl|\n","+-----+-----+------+---+\n","|    0|  974| 36332|0.0|\n","|    0|  980|258610|0.0|\n","|    0| 1004|209887|0.0|\n","|    0| 1005|191172|0.0|\n","|    0| 1028|  9854|0.0|\n","+-----+-----+------+---+\n","only showing top 5 rows\n","\n","+-----+------+------+---+\n","|label| node1| node2| sl|\n","+-----+------+------+---+\n","|    1|  1606|  1611|1.0|\n","|    1| 78935| 78936|1.0|\n","|    1|117647|117649|1.0|\n","|    1|140285|140286|1.0|\n","|    1|187648|187649|1.0|\n","+-----+------+------+---+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wg6shFo0YTHU"},"source":["# Save train and test DataFrames"]},{"cell_type":"markdown","metadata":{"id":"kUrJkmFTAZaH"},"source":["- Join the graph topology features df with the community feature df."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIz27oaoAfin","executionInfo":{"status":"ok","timestamp":1623163071132,"user_tz":-120,"elapsed":15881,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}},"outputId":"47eca856-daba-47e0-9f1e-321c5852a911"},"source":["#@title Solution\n","\n","print('Counts before joining df: ')\n","print(df_train_under_graph_f.count())\n","print(df_train_under_community_f.count())\n","\n","print(df_test_under_graph_f.count())\n","print(df_test_under_community_f.count())\n","\n","df_train_under = df_train_under_graph_f.join(df_train_under_community_f, on=['node1', 'node2', 'label'], how='inner')\n","df_test_under = df_test_under_graph_f.join(df_test_under_community_f, on=['node1', 'node2', 'label'], how='inner')\n","\n","print('Counts after joining df: ')\n","print(df_train_under.count())\n","print(df_test_under.count())"],"execution_count":179,"outputs":[{"output_type":"stream","text":["Counts before joining df: \n","162234\n","162234\n","121380\n","121380\n","Counts after joining df: \n","162234\n","121380\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LCJ2oY5k_rHy"},"source":["Save our final train and test DataFrames to CSV files for use in the next notebook.\n"]},{"cell_type":"code","metadata":{"id":"aO8I7WZKpJHd","executionInfo":{"status":"ok","timestamp":1623163180002,"user_tz":-120,"elapsed":59800,"user":{"displayName":"Raphaël Azorin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1zZn5o5tIlK5J3P6RdcBMqTBjo6bOd2udjj0W=s64","userId":"12399453063503639914"}}},"source":["df_train_under.write.csv(save_folder +  \"df_train_under_all.csv\", mode='overwrite', header=True)\n","df_test_under.write.csv(save_folder + \"df_test_under_all.csv\", mode='overwrite', header=True)"],"execution_count":180,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HgwF_gOeAPQZ"},"source":["Please check that both datasets have been written to your Drive at the desired location because we are going to need them later for model training and testing."]}]}